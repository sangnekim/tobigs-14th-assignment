{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch 패키지\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary #model summary\n",
    "\n",
    "#경고문구 무시\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet class\n",
    "#'Imagenet' data의 class가 1000개 이므로 default: num_classes=1000\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet,self).__init__()\n",
    "        #Convolution Layers\n",
    "        self.features = nn.Sequential(\n",
    "            #convolution layer 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=96,kernel_size=11,stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            #convolution layer 2\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            #convolution layer 3\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #convolution layer 4\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #convolution layer 5\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        #Fully-connected Layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.features(x) #Convolution\n",
    "        x = torch.flatten(x, 1) #1차원 벡터로\n",
    "        x = self.classifier(x) #MLP\n",
    "        return F.log_softmax(x) #softmax 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
      "              ReLU-2           [-1, 96, 55, 55]               0\n",
      "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
      "            Conv2d-4          [-1, 256, 27, 27]         614,656\n",
      "              ReLU-5          [-1, 256, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 256, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         885,120\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n",
      "             ReLU-10          [-1, 384, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "           Linear-14                 [-1, 4096]      37,752,832\n",
      "             ReLU-15                 [-1, 4096]               0\n",
      "           Linear-16                 [-1, 4096]      16,781,312\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "           Linear-18                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 10.99\n",
      "Params size (MB): 237.95\n",
      "Estimated Total Size (MB): 249.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Net = AlexNet() #AlexNet 인스턴스 생성\n",
    "summary(Net, (3, 227, 227)) #모델 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 개요\n",
    " - 합성곱층 (3,227,277) -> (256, 6, 6)\n",
    " - 1차원 벡터로 변환\n",
    " - FC층 (1,9216) -> (1,1000)\n",
    "### Parameter\n",
    " - 활성화층과 풀링층에서 parameter가 0 개인것을 확인할 수 있다\n",
    " - 과제1(pdf참고해서 직접 계산한값)과 같은 결과를 보여준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet 고찰?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
      "              ReLU-2           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 61,100,840\n",
      "Trainable params: 61,100,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 8.49\n",
      "Params size (MB): 233.08\n",
      "Estimated Total Size (MB): 242.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "torchNet = models.AlexNet()\n",
    "summary(torchNet, (3, 227, 227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직접 구현한 AlexNet과 pytorch에서 구현되있는 AlexNet에 차이가 있음을 확인할 수 있다\n",
    " - 차이점1: 합성곱층에서 channel의 수\n",
    " - 차이점2: AdaptiveAvgPooing\n",
    "### 차이점 1\n",
    " - 원래의 AlexNet은 2개의 GPU로 모델을 병렬처리해서 학습을 진행한다\n",
    " - pytorch에서 구현한 AlexNet은 합성곱층은 데이터를 배치로 나눠서 n개의 GPU로 학습을 하고, 이후 FC층에서 모델을 병렬처리해서 n개의 GPU로 학습을 한다\n",
    " - 즉, 모델을 병렬처리하는 원래 모델 vs 데이터를 병렬 처리해서 학습 후 FC층에서 모델을 병렬 처리해서 학습 -> multi gpu\n",
    " - 참조1) pytorch github: https://github.com/pytorch/vision/pull/463#issuecomment-379214941\n",
    " - 참조2) Alex Krizhevsky(AlexNet만든 사람)의 multi-gpu사용 논문 One weird trick for parallelizing convolutional neural networks: https://arxiv.org/pdf/1404.5997.pdf\n",
    "### 차이점 2\n",
    " - AdaptiveAveragePooling을 이용해 GAP(Global Average Pooling)의 효과를 얻으려 한것으로 예상된다 (정확한 정보 아닙니다)\n",
    " - 1차원 벡터로 변환될 때 손실되는 정보를 보완하기 위해 이용하는 것으로 예상된다\n",
    " - 참조1) pytorch,tensorflow에서 GAP: https://underflow101.tistory.com/41\n",
    " - 참조2) GAP&CAM이란? :https://poddeeplearning.readthedocs.io/ko/latest/CNN/CAM%20-%20Class%20Activation%20Map/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
